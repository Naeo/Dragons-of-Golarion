#!/use/bin/python3

"""
CLI Python script to take English input text, generate an IPA
phonetic rendering with eSpeak, and very roughly transliterate 
intoto one of several non-Latin script.  The transcriptions are
meant to be "good enough" for basic flavor text--this is NOT
meant, and is likely not suitable, for serious transliteration
work.

REQUIRES that eSpeak, a free and open source text-to-speech 
synthesizer, be installed, and that the eSpeak executable
be in your system's PATH variable.

REQUIRES Python 3.5 or later

Requires no third-party Python libraries.
"""

import argparse
from copy import deepcopy
import sys
import subprocess

USUAL_ENGLISH_SOUNDS = [
    'a', 'b', 'd', 'e', 'f', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 
    'p', 'r', 's', 't', 'u', 'v', 'w', 'z', 'Ã¦', 'Ã°', 'Å‹', 'É', 'É‘', 
    'É”', 'É™', 'Éš', 'É›', 'Éœ', 'g', 'Éª', 'É¹', 'É¾', 'Êƒ', 'ÊŠ', 'ÊŒ', 'Ê’', 
    'Ê”', 'Ëˆ', 'ËŒ', 'Ë', 'Ì©', 'Î¸', 'áµ»']


AVESTAN_IPA = {
    'eË': 'ğ¬‰', 'oË': 'ğ¬‹', 'É’': 'ğ¬‚', 'g': 'ğ¬”', 'Êƒ': 'ğ¬±', 'aË': 'ğ¬', 
    'tÌš': 'ğ¬', 'r': 'ğ¬­', 'Å‹Ê²': 'ğ¬£', 'É”': 'ğ¬Š', 'uË': 'ğ¬', 'z': 'ğ¬°', 
    'ÊŠ': 'ğ¬', 'h': 'ğ¬µ', 'Å‹': 'ğ¬§', 'mÊ°': 'ğ¬©', 'Î²': 'ğ¬¡', 'mÌ¥': 'ğ¬©', 
    'É²': 'ğ¬¦', 'e': 'ğ¬ˆ', 'j': 'ğ¬«', 'É’Ë': 'ğ¬ƒ', 'd': 'ğ¬›', 'a': 'ğ¬€', 
    'gÊ²': 'ğ¬•', 's': 'ğ¬¯', 'ÉŸ': 'ğ¬•', 'b': 'ğ¬ ', 'uuÌ¯': 'ğ¬ğ¬', 't': 'ğ¬™', 
    'Ê’': 'ğ¬²', 'tÊƒ': 'ğ¬—', 'p': 'ğ¬', 'iË': 'ğ¬', 'v': 'ğ¬¬', 'Éª': 'ğ¬Œ', 
    'É™Ë': 'ğ¬‡', 'Ã§': 'ğ¬’', 'dÊ’': 'ğ¬˜', 'xÊ·': 'ğ¬“', 'f': 'ğ¬Ÿ', 'Î¸': 'ğ¬š', 
    'iiÌ¯': 'ğ¬Œğ¬Œ', 'xÊ²': 'ğ¬’', 'x': 'ğ¬‘', 'Ã£': 'ğ¬…', 'Ã°': 'ğ¬œ', 'm': 'ğ¬¨', 
    'n': 'ğ¬¥', 'É™': 'ğ¬†', 'Å‹Ê·': 'ğ¬¤', 'Ê‚': 'ğ¬´', 'É•': 'ğ¬³', 'k': 'ğ¬', 'l':'ğ¬®',
    'w':'ğ¬ğ¬', ".":"ğ¬½", ";":"ğ¬»", ":":"",
    
    # some custom ones, since cleaning with .replace would be too hard
    'i': 'ğ¬', 'u':'ğ¬', 'o':'ğ¬‹', 'É”Ë': 'ğ¬Š',
}
AVESTAN_CLEANER = {
    "É¹":"r",
    "É›":"e",
    "É‘":"a",
    "Ã¦":"a",
    "áµ»":"Éª",
    "ÊŒ":"É™:",
    "É":"a",
    "Éœ":"e",
    "Éš":"É™r",
    "É¾":"d", # trilled R already used for rhotic, so flap to d, I guess
    "nÌ©":"n",
    "Ê”":"" # no good glottal stop representation    
}
AVESTAN_KEEPABLE = frozenset({
    "'", "\"", "ğ¬º", " "
})

GEORGIAN_CLEANER = {
    "Éš":"É™r", 
    "É¹":"r",
    "Éœ":"É›r",
    "ÊŒ":"É™",
    "Éª":"i",
    "ÊŠ":"u",
    "É":"a",
    "áµ»":"i",
    "Å‹":"ng",
    "É¾":"d",
    "Ë":"",
}
GEORGIAN_IPA = {
    "a":"áƒ",
    "Ã¦":"áƒ",
    "É‘":"áƒ",
    "b":"áƒ‘",
    "d":"áƒ“",
    "dz":"áƒ«",
    "dÊ’":"áƒ¯",
    "e":"áƒ±",
    "eÉª":"áƒ±",
    "É™":"áƒ·",
    "É›":"áƒ”",
    "f":"áƒ¶",
    "g":"áƒ’", # not a regular G--is the IPA G, different codepoint
    "g":"áƒ’",
    "É£":"áƒ¦",
    "h":"áƒ°",
    "i":"áƒ˜",
    "j":"áƒ²",
    "je":"áƒ²",
    "k":"áƒ¥",
    "kÊ°":"áƒ¥",
    "kÊ¼":"áƒ™",
    "l":"áƒš",
    "m":"áƒ›",
    "n":"áƒœ",
    "o":"áƒµ",
    "Å“":"áƒ",
    "É”":"áƒ",
    "pÊ°":"áƒ¤",
    "pÊ¼":"áƒ",
    "p":"áƒ¤",
    "Î¸":"áƒ´", # originally qh
    "Ã°":"áƒ§", # originally q'
    "r":"áƒ ",
    "s":"áƒ¡",
    "Êƒ":"áƒ¨",
    "t":"áƒ—",
    "tsÊ°":"áƒª",
    "tsÊ¼":"áƒ¬",
    "tÊƒÊ°":"áƒ©",
    "tÊƒÊ¼":"áƒ­",
    # "t":"áƒ¢",
    "u":"áƒ£",
    "ui":"áƒ³",
    "v":"áƒ•",
    "w":"áƒ³",
    "y":"áƒ£",
    "z":"áƒ–",
    "Ê’":"áƒŸ",
    "Ê”":"áƒ¸",
    "Ï‡":"áƒ®",
}
GEORGIAN_KEEPABLE = frozenset({".", ",", ":", ";", "?", "!", " "})

TIFINAGH_CLEANER = {
    ":":"",
    "áµ»":"i",
    "É¹":"r",
    "É":"a", 
    "Éœ":"er", 
    "É¾":"d",
    "É›":"e",
    "Éš":"er", 
    "Éª":"i",
    "É”":"o", 
    "É‘":"a",
    "Ê”":"",
    "!":".", # looks too much like ng letter
    "Ë":""
}
TIFINAGH_IPA = {
    "Ã¦":"â´°",
    "b":"â´±",
    # "b":"âµ€", # tuareg yab
    "d":"â´·",
    "Ã°":"â´¸",
    "dÍ¡Ê’":"â´µ",
    "dÍ¡Ê’":"â´¶",
    "dË¤":"â´¹",
    "Ã°Ë¤":"â´º",
    "e":"âµ¦",
    "É™":"â´»",
    "f":"â´¼",
    "g":"â´³",
    "É£":"â´´",
    "ÊŒ":"âµ–", # originally É£
    # "É£":"âµ—",
    "ÊŠ":"âµ˜", # originally É£
    # "h":"âµ",
    "h":"âµ‚",
    # "h":"âµ€",
    "Ä§":"âµƒ",
    "i":"âµ‰",
    "j":"âµ¢",
    "k":"â´½",
    "k":"â´¾",
    "l":"âµ",
    "m":"âµ",
    "n":"âµ",
    "nj":"âµ",
    "Å‹":"âµ‘",
    "o":"âµ§",
    "p":"âµ’",
    "q":"âµ‡",
    "q":"âµˆ",
    "r":"âµ”",
    "rË¤":"âµ•",
    "s":"âµ™",
    "sË¤":"âµš",
    "Êƒ":"âµ›",
    "t":"âµœ",
    "tÍ¡Êƒ":"âµ",
    "tË¤":"âµŸ",
    "v":"âµ ",
    "u":"âµ“", # originally w
    "w":"âµ¡",
    "Ê·":"Â âµ¯",
    "x":"â´¿",
    "z":"âµ£",
    # "z":"âµ¤",
    "zË¤":"âµ¥",
    # "Ê’":"âµŠ",
    # "Ê’":"âµ‹",
    # "Ê’":"âµŒ",
    "Ê’":"âµ˜",
    "a":"âµ„", # originally Ê•
    "Î²":"â´²",
    "Î¸":"âµ",
     "Ï‡":"âµ†",
     # "Ï‡":"âµ…",
}
TIFINAGH_KEEPABLE = frozenset(
    {".", ",", ";", "?", " "}
)

ELDERFUTHARK_IPA = {
    "f":"áš ",
    "u":"áš¢",
    "Ã°":"áš¦",
    "Î¸":"áš¦",
    "a":"áš¨",
    "r":"áš±",
    "k":"áš²",
    "g":"áš·",
    "w":"áš¹",
    # "h":"ášº",
    "h":"áš»",
    "n":"áš¾",
    "i":"á›",
    "j":"á›ƒ",
    "Ã¦":"á›‡",
    "p":"á›ˆ",
    "z":"á›‰",
    # "s":"á›Š",
    "s":"á›‹",
    "t":"á›",
    "b":"á›’",
    "e":"á›–",
    "m":"á›—",
    "l":"á›š",
    # "Å‹":"á›œ",
    "Å‹":"á›",
    "d":"á›",
    "o":"á›Ÿ",
}
ELDERFUTHARK_CLEANER = {
    "Ë":"",
    "Éš":"er", 
    "É¹":"r",
    "Éœ":"er",
    "ÊŒ":"u",
    "Éª":"i",
    "ÊŠ":"u",
    "É":"a",
    "áµ»":"i",
    "Å‹":"ng",
    "É¾":"d",
    "É‘":"a",
    "É›":"e",
    "É™":"e",
    "Ê”":"",
    "v":"f",
    "Ê’":"zh",
    "Êƒ":"sh",
    "É”":"a",
}
ELDERFUTHARK_KEEPABLE = frozenset({';', '!', '?', ':', '.', ','})

MEDEIVALRUNES_IPA = {
    'a':'á›†',
    'b':'á›’',
    'c':'á›',
    'd':'á›‘',
    'e':'á›‚',
    'f':'áš ',
    'g':'ášµ',
    'h':'áš¼',
    'i':'á›',
    'k':'áš´',
    'l':'á›š',
    'm':'á›˜',
    'n':'áš¿',
    'o':'áš®',
    'p':'á›•',
    'p':'á›”',
    'q':'á›©',
    'r':'áš±',
    's':'á›‹',
    't':'á›',
    'u':'áš¢',
    'v':'áš¡',
    'v':'áš¢',
    'w':'áš¥',
    'x':'á›ª',
    'y':'áš¤',
    'y':'á›¨',
    'y':'á›¦',
    'z':'á›',
    'th':'áš¦',
}
MEDEIVALRUNES_CLEANER = {
    "j":"i",
}
MEDEIVALRUNES_KEEPABLE = frozenset({';', '!', '?', ':', '.', ','})

# collect languages into a dict to more programmatically reference
# them later
IPAS = {
    "avestan":AVESTAN_IPA,
    "georgian":GEORGIAN_IPA,
    "tifinagh":TIFINAGH_IPA,
    "elder_futhark":ELDERFUTHARK_IPA,
    "medeival_runes":MEDEIVALRUNES_IPA,
}
CLEANERS = {
    "avestan":AVESTAN_CLEANER,
    "georgian":GEORGIAN_CLEANER,
    "tifinagh":TIFINAGH_CLEANER,
    "elder_futhark":ELDERFUTHARK_CLEANER,
    "medeival_runes":MEDEIVALRUNES_CLEANER,
}
KEEPABLES = {
    "avestan":AVESTAN_KEEPABLE,
    "georgian":GEORGIAN_KEEPABLE,
    "tifinagh":TIFINAGH_KEEPABLE,
    "elder_futhark":ELDERFUTHARK_KEEPABLE,
    "medeival_runes":MEDEIVALRUNES_KEEPABLE,
}

def simple_transliterate(text, textdict, keepable):
    """
    A simple .replace()-based transliteration.
    """
    
    keys = textdict.keys()
    # replace long vowels first if applicable
    keys_1 = sorted([i.strip() for i in keys if "Ë" in i], key=len, reverse=True)
    keys_2 = sorted([i.strip() for i in keys if "Ë" not in i], key=len, reverse=True)

    text_old = text
    for i in keys_1:
        text = text.replace(i, textdict[i])
    for i in keys_2:
        text = text.replace(i, textdict[i])
        
    errs = {
        i 
        for i in set(text_old)
        if i.strip()
        and i in set(text)
        and i not in keepable
    }
    #assert len(errs) == 0, "ERROR: the following characters have no defined mapping: {} \nin\n {}".format(errs, text)
    assert len(errs) == 0, "ERROR: the following characters have no defined mapping: {}".format(errs)
        
    return text

def clean_text(text, cleandict):
    """
    Clean up IPA so it conforms to Avestan characters.
    """
    # FIRST AND FOREMOST: replace lines that are just the explicitly
    # read punctuation.
    text = text.replace("\n dËˆÉ’t\n", ".")
    text=  text.replace("\n pËˆiÉ™É¹ÉªÉ™d\n", ".")
    text = text.replace("\n kËˆÉ‘ËmÉ™\n", ",")
    text = text.replace("\n kËˆoÊŠlÉ™n\n", ":")
    text = text.replace("\n sËŒÉ›mÉªkËˆÉ™ÊŠlÉ™n\n", ";")
    text = text.replace("\n sËŒÉ›mÉªkËˆoÊŠlÉ™n\n", ";")
    text = text.replace("\n kwËˆÉ›stÊƒÉ™n\n", "?")
    text = text.replace("\n ËŒÉ›ksklÉ™mËˆeÉªÊƒÉ™n\n", "!")
    text = text.replace("\n kwËˆoÊŠt\n", "'")
    text = text.replace("\n kwËˆoÊŠts\n", "\"")
    
    text = text.replace("ËŒ", "")
    text = text.replace("Ëˆ", "")
    text = text.replace("Ì©", "") # syllabic marker
    text = text.replace("É¡", "g") # IPA 'g', not regualr 'g'--different code point, this one causes trouble a lot

    for i in cleandict: text = text.replace(i, cleandict[i])
    
    text = text.replace("\n", "")
    
    return text
    
def main():
    parser = argparse.ArgumentParser(
        # usage="python3 transliterator.py [options]"
    )
    parser.add_argument(
        "script", 
        # "-s", 
        type=str, 
        metavar="script",
        choices=list(IPAS.keys()),
        help="The script into which to transliterate. Valid options are: {}"\
              .format("'" + "', '".join(IPAS.keys()) + "'")
        
    )
    parser.add_argument(
        "--input", 
        "-i", 
        type=str,
        metavar="input",
        help="File containing raw English text to transliterate.  "
             "If --text is passed, this is raw input instead; if --stdin is passed, "
             "read input from stdin instead."
    )
    parser.add_argument(
        "--outfile", 
        "-o", 
        type=str, 
        metavar="FILENAME",
        help="Optional, file to dump results to.  Defaults to stdout."
    )
    parser.add_argument(
        "--espeak", 
        type=str, 
        metavar="/path/to/eSpeak/executable",
        default="espeak", 
        help="Full path of the location of your eSpeak binary, if it's not in your PATH variable.  Optional."
    )
    parser.add_argument(
        "--text", 
        "-t", 
        action="store_true",
        help="If passed, treat input argument as raw text rather than a filename."
    )
    parser.add_argument(
        "--stdin", 
        action="store_true", 
        help="If passed, read input from stdin.  Useful for piping text from other commands.  Implies --text."
    )
    parser.add_argument(
        "--ipa", 
        action="store_true", 
        help="If passed, the provided text is already in IPA transcribed format and does NOT need to be run through eSpeak."
    )
    args = parser.parse_args()

    # check that eSpeak is installed
    try:
        subprocess.run([args.espeak, "--version"], stdout=subprocess.PIPE)
    except FileNotFoundError:
        print("ERROR!  You must install eSpeak for this to program to "
              "work.  \nIf you have eSpeak installed, make sure you've "
              "added it to your \nsystem's PATH variable, or explicitly "
              "pass the full path to the binary \nwith the --espeak "
              "flag.")
        exit()
    
    # Parse the input text per CLI arguments.
    if args.stdin:
        orig = sys.stdin.read()
    elif args.text:
        orig = args.input
    else:
        orig = open(args.input, "r", encoding="utf8").read()
    
    # Current hacky check for medeival runes, which can be done as
    # a letter-by-letter substitution on the raw text--no eSpeak
    # transcription needed.
    if args.script == "medeival_runes":
        text = clean_text(orig.lower(), CLEANERS[args.script])
        text = simple_transliterate(text.lower(), IPAS[args.script], KEEPABLES[args.script])
        return text, args.outfile
    
    # Split at newlines--eSpeak does line breaks at prosodic boundaries,
    # so doing this lets us preserve the original line breaks.
    orig = [i for i in orig.split('\n') if i.strip()]
    
    # Make a deep copy so we can zip back up later for auto LaTeX formatting
    text = deepcopy(orig)
    
    # use eSpeak to get ipa renderings of text
    if not args.ipa:
        text = [
            subprocess.run([args.espeak, "-q", "--ipa", "-v", "en-us", i], stdout=subprocess.PIPE).stdout
            for i in text
        ]
        text = [str(i, encoding="utf8") for i in text]
    
    # Do the cleaning and transliteration steps, rejoin and return text
    text = [clean_text(i, CLEANERS[args.script]) for i in text]
    text = [simple_transliterate(i, IPAS[args.script], KEEPABLES[args.script]) for i in text]
    text_final = "\n\n".join(i.strip() for i in text)
    
    # for outputting stuff to a .tex file--uses some macros I've defined,
    # so this probably won't work and isn't needed for you.
    # text_final = "\n\n".join("{{{}}}\n&\n{{\\tifinagh {}}} \\\\".format(i.strip(),j.strip()) for i,j in zip(orig, text))
    
    return text_final, args.outfile

if __name__ == "__main__":
    text, outfile = main()
    if outfile:
        with open(outfile, "w", encoding="utf8") as F:
            F.write(text)
    else:
        print(text)
